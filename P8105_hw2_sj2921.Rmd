---
title: "p8105_hw2_sj2921"
author: "Shan Jiang"
date: "10/3/2018"
output: github_document
---

## Problem 1

- import data from csv file and do some cleaning.
```{r 1.1, message = FALSE}
library(tidyverse)
  
NYC_Transit <- 
    read_csv(file = "./dataset_import/NYC_Transit_Subway_Entrance_And_Exit_Data.csv")
    NYC_Transit <- janitor::clean_names(NYC_Transit)

## Retain line, station, name, station latitude / longitude, routes served, entry, vending, entrance type, and ADA compliance.

NYC_df <- select(NYC_Transit, line, station_name, station_latitude, station_longitude, route1:route11, entry, exit_only, vending, entrance_type, ada)

```

- Convert the entry variable from character (YES vs NO) to a logical variable
```{r 1.2}
# The conversion to logical variable.
NYC_df$vending <- 
  ifelse(NYC_Transit$vending == "YES", TRUE, FALSE)
NYC_df$entry <- 
  ifelse(NYC_Transit$entry == "YES",TRUE, FALSE)
```
* **Brief summary of data**: this dataset contains the basic information in NYC metro, includes the Subway line(street/avenue), station name, the latitude and longtitude of each station, and the routes existed. 
Besides, the subset also contains if there is entry or vending for each station, the type of entrance and if is compliant with Americans with Disabilities Act.

* **Data cleaning steps**: 
1. Import data from selected sheet;
2. Use `Janitor:: clean names` as efficient way to clean variable names;
3. Adopt the select to retain the variables in need.
After doing this, the data is basically readable, however, it's not clean enough.

* **Dimension**: there are 20 column as variables and 1868 rows as observations in the dataset.
 
## Question (Problem1.1):
```{r 1.3}
# Distinct stations in the dataset as of 465;
stations <- nrow(distinct(NYC_df, line, station_name))

# stations are ADA compliant as of 84;
ADA_no <- NYC_df %>% 
   filter(NYC_df$ada == TRUE) %>%
   distinct(line, station_name) 


# The propotion of station entrances/exits without vending allow entrance is 3.94%
No_vd <- NYC_df %>% 
   filter(NYC_df$vending == FALSE) %>%
   filter(entry == TRUE) 
Percent <- (nrow(No_vd) / sum(NYC_df$entry))
```
1. According to above, there are `r stations` distinct stations in NYC. 
2. Also, through filtering we can know that there are `r nrow(ADA_no)` stations which are ADA compliant.
3. The proportion of station entrances/exits without vending allow entrance is `r Percent`.

* Reformat data as NYC_tidy_data
```{r 1.4}
# Make wide data turn to long data, route number and route name are distinct variables.
NYC_tidy_data <- NYC_df %>% 
    gather(key = route_name, value = route_number, 5:15) 

# 60 distinct stations serve the A train
route_A <- 
  NYC_tidy_data %>%
  distinct(line, station_name, station_name,.keep_all = TRUE) %>% 
  filter(route_number == "A") 

# Of the stations that serve the A train, 17 are ADA compliant
ADA_compliant <- NYC_tidy_data %>%
  filter(route_number == "A") %>% 
  distinct(line, station_name, station_name,.keep_all = TRUE)%>% 
  filter(ada == TRUE) 


```
1. `r nrow(route_A)` distinct stations serve the A train;
2. Of the stations that serve the A train, `r nrow(ADA_compliant)` are ADA compliant.

## Problem 2
* Read and clean the Mr. Trash Wheel sheet:
```{r 2.1}
# Load the sheet and specify the range to omit the notes.
library(tidyverse)
library(readxl)
trw_df <- readxl::read_excel(path =   "./dataset_import/HealthyHarborWaterWheelTotals2018-7-28.xlsx",sheet = 1, range = "A2:N338")

# Clean variable names 
trw_df <- janitor::clean_names(trw_df)

# omit rows that do not include dumpster-specific data
trw_df <- trw_df %>% 
  filter(trw_df$dumpster != "NA") 

# rounds the number of sports balls to the nearest integer and converts the result to an integer variable (using as.integer)
trw_df$`sports_balls` <- 
  as.integer(round(trw_df$`sports_balls`, digits = 0))

```

* import precipitation data in 2016 & 2017 
```{r 2.2}
# Read 2017 precipitation data, clean names of variable, add a variable as year 2017
Precp_17 <- 
  readxl::read_excel(path =   "./dataset_import/HealthyHarborWaterWheelTotals2018-7-28.xlsx",sheet = 4, skip = 1) %>% 
  janitor::clean_names() %>% 
  filter(total != "NA", month != "NA") %>% 
  mutate(year = 2017)


# Read 2016 precipitation data, clean names of variable, add a variable as year 2016
Precp_16 <- readxl::read_excel(path =   "./dataset_import/HealthyHarborWaterWheelTotals2017-9-26.xlsx",sheet = 5, skip = 1 ) %>% 
  janitor::clean_names() %>% 
  filter(total != "NA", month != "NA") %>% 
  mutate(year = 2016)

## combine datasets and rename the variable:
Precp <- right_join(Precp_17, Precp_16, by = "month") 
  
names(Precp)[3] <- "Year1"  
names(Precp)[5] <- "Year2" 

names(Precp)[2] <- "Precipitation1"
names(Precp)[4] <- "Precipitation2"

# convert month to a character variable (the variable month.name is built into R and should be useful).
Precp$month <- as.character(month.name[Precp$month])

# Combine the new data frame organized.
Precp_df <- 
  Precp %>% 
  select(month, Year1, Precipitation1, Year2, Precipitation2) 

# calculate the total precipitation in 2017
sum_17_precp <- sum(Precp_df$Precipitation1, na.rm = TRUE)

# calculate the median of sportsballs in 2016
Ball_02 <- trw_df %>% 
    filter(year == 2016) 

med_sports <- median(Ball_02$`sports_balls`)
```
key variables
- 
* The number of observations  in 2016 is precpitation data `r nrow(Precp_16)`;
* The number of observations in 2017 precpitation data is  `r nrow(Precp_17)`;
* The total precipitation in 2017 is  `r sum_17_precp `;
* The the median of sportsballs in 2016 is `r med_sports`.

##Problem 3
```{r}
library(p8105.datasets)

# Import the BFRSS data, exclude variables and format the data by using appropriate names.
brfss_df <- 
  brfss_smart2010 %>% 
    janitor::clean_names() %>% 
    select(-class, -topic, -question, -sample_size, -confidence_limit_low:-geo_location ) 

# structure data: Response indicating the proportion of subjects with each response
Percentage <- 
  brfss_df  %>%
  filter(response == "Excellent"  | response == "Very good" | response == "Good" | response == "Fair" | response == "Poor") %>% 
  spread(key = response, value = data_value) %>% 
  janitor::clean_names() %>% 
# create a new variable showing the proportion of responses that were “Excellent” or “Very Good”
  mutate(Ex_good = excellent + very_good) 

# unique locations: Every state is represented in the dataset as there are 51 distinct states in the dataframe.
brfss_df %>% 
   distinct(., locationabbr, .keep_all = TRUE)




# In 2002, what is the median of the “Excellent” response value
```


