---
title: "p8105_hw2_sj2921"
author: "Shan Jiang"
date: "10/3/2018"
output: github_document
---

## Problem 1

- Set the graph properties(theme, color and size) for ggplot
```{r 1.0, message = FALSE, echo= FALSE}
library(tidyverse)
library(readxl)
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_bw() + theme(legend.position = "bottom"))
```
- import NYC Transit data from csv file and do some cleaning.
```{r 1.1, message = FALSE}  
NYC_Transit <- 
    read_csv(file = "./dataset_import/NYC_Transit_Subway_Entrance_And_Exit_Data.csv")
    NYC_Transit <- janitor::clean_names(NYC_Transit)

## Retain line, station, name, station latitude / longitude, routes served, entry, vending, entrance type, and ADA compliance.

NYC_df <- select(NYC_Transit, line, station_name, station_latitude, station_longitude, route1:route11, entry, exit_only, vending, entrance_type, ada)

```
- **Convert** the entry variable from character (YES vs NO) to a logical variable
```{r 1.2}
# The conversion to logical variable.
NYC_df$vending <- 
  ifelse(NYC_Transit$vending == "YES", TRUE, FALSE)
NYC_df$entry <- 
  ifelse(NYC_Transit$entry == "YES",TRUE, FALSE)
```
* **Brief summary of NYC Transit data**: 
- **Dimension**: there are 20 columns as variables and 1868 rows as observations in the dataset.
- NYC Transit Subway Data contains the basic information in NYC metro: it includes the Subway line(street/avenue), station name, the latitude and longtitude of each station, and the routes existed. 
- Besides, the subset also contains if there is entry or vending for each station, the type of entrance and if it is compliant with Americans with Disabilities Act(ADA).

* **Data cleaning steps**: 
1. Import data from selected sheet;
2. Use `Janitor:: clean names` as efficient way to clean variable names, as the r is case sensitive;
3. Adopt the `select` to retain the variables in need;
4. Use `ifelse` to convert the YES/NO data to a logical variable;
5. Use `filter` or `distinct` to find the info that we need.

* **Data evaluation**: After doing this, the data is basically readable, however, it's not clean enough since there are **11 columns** which contain routes spreaded in the dataframe.
 
## Question answers:

```{r 1.3}
#Distinct stations in the dataset as of 465;
stations <- nrow(distinct(NYC_df, line, station_name))
```

```{r}
#stations are ADA compliant as of 84;
ADA_no <- NYC_df %>% 
   filter(NYC_df$ada == TRUE) %>%
   distinct(line, station_name) 
```

```{r}
# The propotion of station entrances/exits without vending allow entrance is 3.77%
No_vd <- NYC_df %>% 
   filter(vending == FALSE) %>%
   filter(entry == TRUE) 
Percent <- (nrow(No_vd) / nrow(filter(NYC_df, vending == FALSE)))
```
1. According to above, there are `r stations` distinct stations in NYC. 
2. Also, through filtering we can know that there are `r nrow(ADA_no)` stations which are ADA compliant.
3. The proportion of station entrances/exits without vending allow entrance is `r Percent`.

* Reformat data as NYC_tidy_data
```{r 1.4}
# Make wide data turn to long data, route number and route name are distinct variables.
NYC_tidy_data <- NYC_df %>% 
    gather(key = route_name, value = route_number, 5:15) 

# 60 distinct stations serve the A train
route_A <- 
  NYC_tidy_data %>%
  distinct(line, station_name, station_name,.keep_all = TRUE) %>% 
  filter(route_number == "A") 

# Of the stations that serve the A train, 17 are ADA compliant
ADA_compliant <- NYC_tidy_data %>%
  filter(route_number == "A") %>% 
  distinct(line, station_name, station_name,.keep_all = TRUE)%>% 
  filter(ada == TRUE) 


```
1. `r nrow(route_A)` distinct stations serve the A train;
2. Of the stations that serve the A train, `r nrow(ADA_compliant)` are ADA compliant.

# Problem 2
* Read and clean the Mr. Trash Wheel sheet:
```{r 2.1}
# Load the sheet and specify the range to omit the notes.
library(tidyverse)
library(readxl)
trw_df <- 
    readxl::read_excel(path =   "./dataset_import/HealthyHarborWaterWheelTotals2018-7-28.xlsx",sheet = 1, range = "A2:N338") %>% # Clean variable names  
    janitor::clean_names() %>% 
    # omit rows that do not include dumpster-specific data
    filter(dumpster != "NA") 

# rounds the number of sports balls to the nearest integer and converts the result to an integer variable (using as.integer)
trw_df$`sports_balls` <- 
  as.integer(round(trw_df$`sports_balls`, digits = 0))

```
**Data Overview**: 
1. There are in total **285** observations and **14** variables in the Mr.Trash Wheel dataframe.
2. Key variables included are month, 

* import precipitation data in 2016 & 2017 
```{r 2.2}
# Read 2017 precipitation data, clean names of variable, add a variable as year 2017
Precp_17 <- 
  readxl::read_excel(path =   "./dataset_import/HealthyHarborWaterWheelTotals2018-7-28.xlsx",sheet = 4, skip = 1) %>% 
  janitor::clean_names() %>% 
  filter(total != "NA", month != "NA") %>% 
  mutate(year = 2017)
```
Combine the datasets in 2016 and 2017
```{r 2.3}
# Read 2016 precipitation data, clean names of variable, add a variable as year 2016
Precp_16 <- readxl::read_excel(path =   "./dataset_import/HealthyHarborWaterWheelTotals2017-9-26.xlsx",sheet = 5, skip = 1 ) %>% 
  janitor::clean_names() %>% 
  filter(total != "NA", month != "NA") %>% 
  mutate(year = 2016)

## combine datasets and rename the variable:
Precp <- right_join(Precp_17, Precp_16, by = "month") 
  
names(Precp)[3] <- "Year1"  
names(Precp)[5] <- "Year2" 

names(Precp)[2] <- "Precipitation1"
names(Precp)[4] <- "Precipitation2"

# convert month to a character variable (the variable month.name is built into R and should be useful).
Precp$month <- as.character(month.name[Precp$month])

# Combine the new data frame organized.
Precp_df <- 
  Precp %>% 
  select(month, Year1, Precipitation1, Year2, Precipitation2) 

# calculate the total precipitation in 2017
sum_17_precp <- sum(Precp_df$Precipitation1, na.rm = TRUE)

# calculate the total precipitation in 2016
sum_16_precp <- sum(Precp_df$Precipitation2, na.rm = TRUE)

# calculate the median of sportsballs in 2016
Ball_02 <- trw_df %>% 
    filter(year == 2016) 

med_sports <- median(Ball_02$`sports_balls`)

```

Some other summary for Mr.Trash.wheel Dataframe...
```{r}
# Mean of Plastic bottles collected in 2017. 
sum_trw <- 
  trw_df %>% 
     filter(year == 2017)  

mean_plastic <- mean(sum_trw$plastic_bottles)
mean_plastic <- round(mean_plastic, digits = 0)

# sum of cigarette butts in the total period.
sum_cig <- sum(trw_df$cigarette_butts, na.rm = TRUE)

#calculate the total weight of trash in the year of 2017
weight_17 <- trw_df %>% 
  filter(year != 2017) 
  
sum_weight <- sum(weight_17$weight_tons)

```

key variables
- 
* The number of observations  in 2016 is precpitation data `r nrow(Precp_16)`;
* The number of observations in 2017 precpitation data is  `r nrow(Precp_17)`;
* The total precipitation in 2017 is  `r sum_17_precp `;
* The total precipitation in 2016 is  `r sum_16_precp `;
* The median of sportsballs in 2016 is `r med_sports`;
* The total weight of dumpster in 2017 is `r sum_weight`;
* The mean of glass bottles in 2017 is `r mean_plastic`;
* The sum of cigrette butts for the last five years are `r sum_cig`.

# Problem 3
-
```{r}
library(p8105.datasets)

# Import the BFRSS data, exclude variables and format the data by using appropriate names.
brfss_df <- 
  brfss_smart2010 %>% 
    janitor::clean_names() %>% 
    select(-class, -topic, -question, -sample_size, -confidence_limit_low:-geo_location ) 

# structure data: Response indicating the proportion of subjects with each response
Percentage <- 
  brfss_df  %>%
  filter(response == "Excellent"  | response == "Very good" | response == "Good" | response == "Fair" | response == "Poor") %>% 
  spread(key = response, value = data_value) %>% 
  janitor::clean_names() %>% 
# create a new variable showing the proportion of responses that were “Excellent” or “Very Good”
  mutate(Exl_good = excellent + very_good) 

# unique locations: 
unique_lc <- brfss_df %>% 
   distinct(., locationdesc, .keep_all = TRUE)

#Every state is represented in the dataset as there are 51 distinct states in the dataframe.
brfss_df %>% 
   distinct(., locationabbr, .keep_all = TRUE)

# Get an order by using group summary: NJ is observed most.
States <- brfss_df %>% 
  group_by(locationabbr) %>% 
  summarize(n = n()) %>% 
  mutate(freq_ranking = min_rank(desc(n))) %>% 
  filter(min_rank(desc(n)) < 2)

# In 2002, the median of the “Excellent” response value: 23.6.
excellent <- 
  brfss_df %>% 
  filter(response == "Excellent" & year == "2002") 

med_excel <- median(excellent$data_value, na.rm = TRUE)
```
## Question answers
1. There are `r nrow(unique_lc)` distinct locations in the dataset; 
2. Every state is represented as 51 distinct values are included for states; 
3. **New Jersey** is observed most. 
4. In 2002, the median of the “Excellent” response value is **`r med_excel`**.


Graph for the BFRSS dataset  
-
```{r}
library(viridis)
## Histrogram of Excellent Response in the Year of 2002
Percentage  %>%
  filter(year == "2002") %>% 
  ggplot(aes(x = excellent )) + 
  geom_histogram(binwidth = 0.7 ) + 
  labs(title = " Excellent response values in the year 2002",
       y = "Response value ",
       caption = "Data from the BRFSS package"
       ) +
  viridis::scale_fill_viridis(name = "Location", 
    discrete = TRUE
  ) +
  theme(legend.position = "bottom")

ggsave("histogram of response value in 2002.png")

## Response as of excellent from year 2002 to 2010
Percentage  %>%
    filter(locationdesc == "NY - New York County" | locationdesc == "NY - Queens County") %>%
    ggplot(aes(x = year, y = excellent)) + 
    geom_smooth(se = FALSE) +
    geom_point(aes(color = locationdesc), alpha = .7) +
  labs(
    title = " Proportion of Excellent response values in New York County and Queens from 2002 to 2010",
    x = "Year",
    y = "Number of excellent (n)",
    caption = "Data from the BRFSS package"
  ) + 
    scale_color_hue(name = "Location",
                   h = c(100, 300)
                 ) +
  facet_grid(. ~locationdesc)

ggsave("02_10NYC_proportion.png")

#summary for plots 
df_nyc <- 
  filter(Percentage, locationdesc == "NY - New York County")

mean_nyc <- round(mean(df_nyc$excellent), digits = 0)

df_qus <- 
  filter(Percentage, locationdesc == "NY - Queens County")

mean_qus <- round(mean(df_qus$excellent), digits = 0)
```
* In the scatter plot, we can see that the NY-New York County gets more excellent response from the 2002 to 2010 than that of the NY-Queens County as the NY-New York County has a mean of `r  mean_nyc` , Queens County has a mean of `r mean_qus`, there exists a gap between the two locations.

* Also, the trend of response value shown in the graph: NYC county residents presents a sharp decrease in response value in excellent while the Queens citizens are showing a fast growing trend from 2008 to 2010, so the gap beween the two is narrowing. 




